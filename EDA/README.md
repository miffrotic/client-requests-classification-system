### Первичный EDA
Мы провели EDA датасета, изучили качество исходных данных и провели базовый анализ клиентских запросов как с помощью визуализаций, так и с помощью алгоритмов кластеризации. 

**Ключевые пункты, которые хочется вынести из исследования:**
> Данные хорошего качества, нет критичных проблем, затрудняющих дальнейшую работу.


В датасете нет пропусков, дубликатов, некорректных значений и т.п., что могло бы помешать в дальнейшей работе.


> Исходя из распределение по числу слов, символов в запросах клиентов, обращения выглядят схожими и немного "синтетическими". Также, каждому сообщению в датасете соответствует один интент и одна категория.


Ключевой инсайт EDA, из которого следует, что **стоит провести аугментацию** - с помощью LLM к текущим данным стоит дополнительно сгенерировать обращения клиентов разной длины и разных эмоциональных окрасов для большей разнообразности. Помимо прочего, клиенты могут задавать одновременно несколько вопросов в одном сообщении, что не учитывается в текущем датасете - это также следует учесть при дополнительной генерации выборки, следует сгенерировать обращения с multi-labeled категориями.


> В текстах обращений клиентов много "лишних" слов, требующих очистки. 


Стандартный стоп-словарь на английском из `nltk` справляется с задачей, но стоит задуматься над более точечным исключением некоторых глаголов (want, help, see и проч.) - эти слова часто имеют высокий вес в кластеризациях, хотя не являются сильно осмысленными и несущими контекст индивидуально. Следует на этапе обучения моделей сравнить качество с ними и без, чтобы принять окончательное решение. 

---

### Аугментация (см. `gen_data_gemini.ipynb`)
Для расширения исходного набора данных была проведена аугментация с использованием модели Gemini 2.5 Flash-Lite через API.

**Процесс генерации:**
*   **Инструмент:** Gemini 2.5 Flash-Lite.
*   **Методология:** Был разработан специализированный промпт, включающий описание структуры и характеристик столбцов исходного датасета.
*   **Параметры:** Для стимулирования генерации разнообразных и нетривиальных примеров были установлены параметры, смещенные в сторону креативности (`"temperature": 0.9`, `"top_p": 0.95`).

**Постобработка и очистка:**
В результате было сгенерировано **13 500** новых записей в формате JSON. В ходе анализа и последующей обработки были устранены следующие артефакты генерации:
1.  **Дублирование категорий:** Записи с повторяющимися метками в рамках одной сущности (например, `['REFUND', 'REFUND']`) были нормализованы до уникальных значений (`['REFUND']`).
2.  **Неконсистентный порядок категорий:** Для multi-label записей с одинаковым набором, но разным порядком меток (например, `['REFUND', 'ORDER']` и `['ORDER', 'REFUND']`), был внедрен единый стандарт сортировки для обеспечения консистентности данных.

---

### Итоговый результат
В результате проведенной аугментации и последующей очистки мы получили **существенно расширенный, чистый и консистентный датасет**. Новые данные не только увеличили объем выборки, но и обогатили ее разнообразными примерами, при этом все сгенерированные артефакты были устранены. Датасет готов к дальнейшему использованию в моделях машинного обучения.
